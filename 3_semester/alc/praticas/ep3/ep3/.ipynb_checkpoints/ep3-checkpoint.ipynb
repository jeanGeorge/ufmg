{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "30fe04fad4f881ddacc44b34f71c815f",
     "grade": false,
     "grade_id": "cell-5802f858353a14fb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Exercício Prático 3: PCA\n",
    "\n",
    "Neste exercício vamos estudar as representações de baixa dimensão obtidas pelo PCA. O objetivo é reproduzir os resultados obtidos usando o módulo sklearn.decomposition.PCA usando apenas o numpy. Para isto, vamos utilizar os dados contidos em ```p1.txt```.\n",
    "\n",
    "O conjunto de dados ```p1.txt``` contém recordes nacionais femininos em corridas de 100m, 200m e 400m rasos em segundos e corridas de longa distância em minutos. Os nomes das variáveis não estão incluídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8e4cb4cec05cc42123f733a3011b169b",
     "grade": false,
     "grade_id": "cell-4190b58ea79cb263",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# lendo os dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "df = pd.read_csv('p1.txt',sep='\\t',header=None,names=[\"Country\",\"100m\",\"200m\",\"400m\",\"800m\",\"1500m\",\"3000m\",\"Marathon\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1c11c44f0ba68e68f3550628789949ba",
     "grade": false,
     "grade_id": "cell-d4bf8b1d4c8964aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# extraindo a matriz de dados e os nomes dos países\n",
    "X = df.drop('Country',axis=1).as_matrix()\n",
    "countries = list(df['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f44df4f3528ac0729db5050d422fc5a1",
     "grade": false,
     "grade_id": "cell-73b681d48cfb2caa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão resolvida\n",
    "\n",
    "Para cada variável (coluna), calcule a média usando ```np.mean``` e a variância usando ```np.var```. Use a função ```np.round``` para arredondar o resultado para 3 casas decimais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6b7e8ef6706a36c7357f10750a053654",
     "grade": false,
     "grade_id": "cell-565714b9f7bdde0a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# calculando a média mu e a variância sigma2 (o ddof=1 é usado para que o denominador seja m-1)\n",
    "\n",
    "mu = np.mean(X,axis=0)\n",
    "sigma2 = np.var(X,axis=0,ddof=1)\n",
    "\n",
    "print(mu)\n",
    "print(sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "df6ae458ac994f3e662e7b01ddd491e9",
     "grade": false,
     "grade_id": "cell-fc7e4588f578ed6c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão resolvida\n",
    "\n",
    "Transforme a matriz ```X``` em ```X_centered``` subtraindo a média de cada variável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "757e98d8e9b983b70bd7db5c1090d510",
     "grade": false,
     "grade_id": "cell-5118ef8504543054",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# neste caso, a subtração entre matriz e vetor faz com que o vetor seja subtraído de cada linha da matriz\n",
    "\n",
    "m,n = X.shape\n",
    "#Mu = mu.repeat(m).reshape((n,m)).T\n",
    "X_centered = X-mu\n",
    "X_centered[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "517bb04daa1c334e75bfb98f60bcf244",
     "grade": false,
     "grade_id": "cell-8d38882f5280a54c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão resolvida\n",
    "\n",
    "Agora normalize a matriz ```X_centered``` dividindo cada entrada pelo seu desvio padrão. Salve o resultado em ```X_normalized```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55faa634ddc4cc461d82b3d005f494e7",
     "grade": false,
     "grade_id": "cell-f9c51eca92ab6463",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# neste caso, a divisão entre matriz e vetor faz com que cada linha da matriz seja dividida elemento-a-elemento pelo vetor\n",
    "\n",
    "sigma = np.sqrt(sigma2)\n",
    "#Sigma = sigma.repeat(m).reshape((n,m)).T\n",
    "X_normalized = X_centered/np.sqrt(sigma2)\n",
    "X_normalized[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e410ef6fe549e1b94b534b06c3259584",
     "grade": false,
     "grade_id": "cell-cc2e8dfe5ab74a39",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão 1\n",
    "\n",
    "Defina uma matriz que receba como entrada uma matriz $\\mathbf{A}_{m \\times n}$ de $m$ observações por $n$ variáveis que já foi centralizada e normalizada e retorne a matriz de covariância das variáveis. A função **não pode** utilizar a função ```numpy.cov```, mas sim utilizar a fórmula vista em sala ($m-1$ como denominador)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fc63b64de97f00071511a2f62f66760b",
     "grade": false,
     "grade_id": "cell-91a09055d06bcd96",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculaCov(A):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "549533eee38479713e9c87fadef142e3",
     "grade": false,
     "grade_id": "cell-3ec6b54ab4e534eb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Certifique-se de que o resultado para a matriz ```X_normalized``` é igual aquele encontrado no arquivo ```cov.npz```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0d854193542d318e9ad994f3fbc8c0ad",
     "grade": true,
     "grade_id": "cell-b600d280016f7f07",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cov = calculaCov(X_normalized)\n",
    "with open('cov.npz','rb') as f: \n",
    "    saida = np.load(f)\n",
    "\n",
    "assert np.allclose(cov,saida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "110a9b8c6de3d2b7b063c2d191715105",
     "grade": false,
     "grade_id": "cell-b93e0acb3a754ef9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão 2\n",
    "\n",
    "Vamos construir a matriz $P = E^\\top$ contendo as duas componentes principais. \n",
    "Para isso, você deve obter os dois autovetores dos maiores autovalores em módulo da matriz ```cov``` usando ```np.linalg.eig```.\n",
    "\n",
    "O resultado obtido usando PCA é mostrado a seguir. É possível que alguns autovetores/componentes tenham sinais opostos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a005215748a9c1799cbb6bec7ca72907",
     "grade": false,
     "grade_id": "cell-24baf5a8f862dffc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X_normalized).transform(X_normalized)\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e523542589ee498200fec6db87ba7d0c",
     "grade": false,
     "grade_id": "cell-7de661c72abbb8cf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculaMatrizP(cov, n_componentes):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5cd9587e052e54ca9af054d4691e84d6",
     "grade": true,
     "grade_id": "cell-2343740bbde73d49",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "P = calculaMatrizP(cov, 2)\n",
    "print(P)\n",
    "\n",
    "assert (\n",
    "    np.allclose(P[0],pca.components_[0]) or np.allclose(P[0],-pca.components_[0])\n",
    ") and (\n",
    "    np.allclose(P[1],pca.components_[1]) or np.allclose(P[1],-pca.components_[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f878f06f86627153bfd823ce99a336e2",
     "grade": false,
     "grade_id": "cell-3860d77cc37b59c4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão 3\n",
    "\n",
    "Calcule a porcentagem da variância total explicada pelo primeiro e segundo componentes principais. Para isto é preciso normalizar os autovalores obtidos no passo anterior pela soma de todos os $n$ autovalores.\n",
    "\n",
    "O resultado obtido usando PCA é mostrado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "010d6751f635a6c039274a52bb286f99",
     "grade": false,
     "grade_id": "cell-9c930b5992b0540e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "aeed1ca487be2449f498c412b5d74c3b",
     "grade": false,
     "grade_id": "cell-5e1d744410fc4fad",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculaVarianciaExplicada(cov, n_componentes):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return var_explicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5d9cdf5c1e324ff7304ff06fd87daf52",
     "grade": true,
     "grade_id": "cell-41b7faf4aa170084",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "var_explicada = calculaVarianciaExplicada(cov, 2)\n",
    "assert np.allclose(var_explicada,pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9b9e66f5d5098fed8895bece038b75c9",
     "grade": false,
     "grade_id": "cell-0a35dc71bc2dfeb5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão 4\n",
    "\n",
    "As linhas de ```P``` formam uma base ortogonal. A projeção das linhas de ```X_normalized``` nas linhas de ```P``` geram uma representação para cada país no plano (PC1, PC2). Construa um diagrama de dispersão 2D das 54 observações no plano (PC1, PC2).\n",
    "\n",
    "O resultado obtido usando PCA é mostrado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2061353c515b22d59d25fdea3ab57bd1",
     "grade": false,
     "grade_id": "cell-1ea29ddcaa4ae2c2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_r = pca.fit(X_normalized).transform(X_normalized)\n",
    "plt.scatter(X_r[:,0],X_r[:,1])\n",
    "for i in range(X_r.shape[0]):\n",
    "    plt.annotate(countries[i],xy=(X_r[i,0],X_r[i,1]),xytext=(0,5),\n",
    "                 textcoords='offset points', ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "aabf2c5e0e227c5596efdd3a7e16dc99",
     "grade": true,
     "grade_id": "cell-904b66840679bdeb",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def plotaDiagramaDispersao(P, X_normalized):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e584d97b27d4155b9534891015180cc3",
     "grade": false,
     "grade_id": "cell-2e015b71e4a84b05",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Questão 5\n",
    "\n",
    "Considerando o gráfico anterior, que país poderia ser considerado um outlier? O nome do país pode ser consultado [aqui](https://countrycode.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8ffbc3a3d018f6981b40e8253f66ccbf",
     "grade": true,
     "grade_id": "cell-3012fddc53a09381",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
